{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29714fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from brokenaxes import brokenaxes\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.ticker import FuncFormatter, LogLocator, MultipleLocator\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from my_favorite_things import (\n",
    "    bar_count,\n",
    "    format_ddict,\n",
    "    multifader,\n",
    "    nested_ddict,\n",
    "    pprint_nested_dict,\n",
    ")\n",
    "from pennylane import numpy as qmlnp\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from scripts.constants import INVMS, NUM_FSP_DICT, SYM_TRUE_BS_DICT, TOP_MASS, W_MASS\n",
    "from scripts.data import get_bitstring_invms, split_data\n",
    "from scripts.events import get_data\n",
    "from scripts.files import load_data, parse_data, verify_data\n",
    "from scripts.hamiltonians import (\n",
    "    get_all_bitstring_energies,\n",
    "    get_bitstring_energies,\n",
    "    get_coefficients,\n",
    "    get_minimum_energies,\n",
    "    swap,\n",
    ")\n",
    "from scripts.hemisphere import run_hemisphere\n",
    "from scripts.pennylane_algs import MAQAOA, VarQITE\n",
    "from scripts.postdata import (\n",
    "    create_falqon_depth,\n",
    "    find_efficiency,\n",
    "    get_2dhist_invms,\n",
    "    get_bitstrings,\n",
    "    parse_with_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a deprecation warning for functools.partial from pennylane and it's just\n",
    "# annoying to see everytime, so we silence it for now\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*functools.partial will be a method descriptor.*\",\n",
    "    category=FutureWarning,\n",
    ")\n",
    "\n",
    "# Print out numpy arrays to be more readable\n",
    "np.set_printoptions(linewidth=200)\n",
    "\n",
    "# Matplotlib formatting params\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.labelsize\": 24,\n",
    "        \"ytick.labelsize\": 18,\n",
    "        \"xtick.labelsize\": 18,\n",
    "        \"figure.subplot.wspace\": 0.25,\n",
    "        \"figure.subplot.hspace\": 0.2,\n",
    "        \"axes.titlesize\": 26,\n",
    "        \"legend.fontsize\": 15,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Fill for Hamiltonian limit\n",
    "FILL_KWARGS = {\"color\": \"#B2B2BF\", \"hatch\": \"x\", \"alpha\": 0.3}\n",
    "COLORS = {\n",
    "    \"qaoa\": \"#68C3D4\",\n",
    "    \"maqaoa\": \"#E84B45\",\n",
    "    \"xqaoa\": \"#762FCD\",\n",
    "    \"falqon\": \"#E3B505\",\n",
    "    \"varqite\": \"#2F923C\",\n",
    "    \"hemisphere\": \"#101010\",\n",
    "    \"annealer\": \"#A7A78B\",\n",
    "}\n",
    "LSS = {\n",
    "    \"qaoa\": \"solid\",\n",
    "    \"maqaoa\": \"solid\",\n",
    "    \"xqaoa\": \"solid\",\n",
    "    \"falqon\": \"solid\",\n",
    "    \"varqite\": \"solid\",\n",
    "    \"hemisphere\": \"dashdot\",\n",
    "    \"annealer\": \"dashed\",\n",
    "}\n",
    "LABELS = {\n",
    "    \"qaoa\": \"QAOA\",\n",
    "    \"maqaoa\": \"ma-QAOA\",\n",
    "    \"xqaoa\": \"XQAOA\",\n",
    "    \"falqon\": \"FALQON\",\n",
    "    \"varqite\": \"VarQITE\",\n",
    "    \"hemisphere\": \"Hemisphere Method\",\n",
    "    \"annealer\": \"Quantum Annealer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e7ec6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "evts_etype = \"ttbar\"\n",
    "evts_dtype = \"parton\"\n",
    "CORRECT = SYM_TRUE_BS_DICT[evts_etype]\n",
    "\n",
    "evts, Jijs, Pijs, invms = get_data(etype=evts_etype, dtype=evts_dtype)\n",
    "split_evts, split_inds = split_data(evts=evts)\n",
    "split_Jijs = Jijs[split_inds]\n",
    "split_Pijs = Pijs[split_inds]\n",
    "split_invms = invms[split_inds]\n",
    "split_H0_coeffs = get_coefficients(hamiltonian=\"H0\", evts=evts)[split_inds]\n",
    "split_H2_coeffs = get_coefficients(\n",
    "    hamiltonian=\"H2\", evts=evts, nume=[\"min\", \"Jij\"], denom=[\"max\", \"Pij\"]\n",
    ")[split_inds]\n",
    "\n",
    "bruteforce_dict = {\n",
    "    \"H0\": [\n",
    "        (get_minimum_energies(evts, hamiltonian=\"H0\")[:, 0] == CORRECT).sum()\n",
    "        / split_evts.shape[1]\n",
    "        for evts in split_evts\n",
    "    ],\n",
    "    \"H2\": [\n",
    "        (\n",
    "            get_minimum_energies(\n",
    "                evts, hamiltonian=\"H2\", nume=[\"min\", \"Jij\"], denom=[\"max\", \"Pij\"]\n",
    "            )[:, 0]\n",
    "            == CORRECT\n",
    "        ).sum()\n",
    "        / split_evts.shape[1]\n",
    "        for evts in split_evts\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b504059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the FALQON data takes up ~100x more space because data is saved\n",
    "# for every of the 2500 depths, so we choose the depths we want\n",
    "falqon_depths = np.sort(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            np.arange(0, 1001, 100)[1:],\n",
    "            np.arange(1000, 2501, 500),\n",
    "            [25, 50, 150, 250, 350, 450, 750],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "num_runs = len(parse_data())\n",
    "data = []\n",
    "metadata = []\n",
    "for ind, metadatum in enumerate(parse_data()):\n",
    "    print(\" \" * 50, end=\"\\r\")\n",
    "    print(\n",
    "        f\"Loading data [{metadatum[0]}]: {ind + 1:>{len(str(num_runs))}} / {num_runs}\",\n",
    "        end=\"\\r\",\n",
    "    )\n",
    "    if not (verify_data(*metadatum)):\n",
    "        print(f\"{metadatum}\\nSkipping!\\n\")\n",
    "        continue\n",
    "\n",
    "    datum = load_data(*metadatum)\n",
    "    if metadatum[0] == \"falqon\":\n",
    "        for depth in falqon_depths:\n",
    "            new_datum, new_metadatum = create_falqon_depth(\n",
    "                datum=datum, metadatum=metadatum, depth=depth\n",
    "            )\n",
    "            data.append(new_datum)\n",
    "            metadata.append(new_metadatum)\n",
    "    else:\n",
    "        data.append(datum)\n",
    "        metadata.append(metadatum)\n",
    "\n",
    "data = np.array(data)\n",
    "metadata = np.array(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa09adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof(datum):\n",
    "    tot_space = 0\n",
    "    for invmd in datum.values():\n",
    "        for val in invmd.values():\n",
    "            tot_space += val.nbytes\n",
    "    return tot_space\n",
    "\n",
    "\n",
    "tot_total = 0\n",
    "for datum, metadatum in zip(data, metadata):\n",
    "    size = sizeof(datum)\n",
    "    tot_total += size\n",
    "    print(f\"{metadatum[0]:<7} ({metadatum[1]:>4}) -- {size / 1e6:>10,.2f} MB\")\n",
    "print(\"-\" * 30 + f\"\\nTotal -- {tot_total / 1e9:,.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = nested_ddict(3, list)\n",
    "for metadatum in metadata:\n",
    "    alg = metadatum[0]\n",
    "    ham = metadatum[2]\n",
    "    evt = f\"{metadatum[4]}_{metadatum[5]}\"\n",
    "    norm = metadatum[3]\n",
    "    depth = metadatum[1]\n",
    "\n",
    "    d[alg][ham][evt][norm].append(int(depth))\n",
    "pprint_nested_dict(format_ddict(d, sort_lists=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data for hemisphere method\n",
    "hemisphere_bitstrings = np.empty_like(split_inds, dtype=\"U6\")\n",
    "for ind, invm_evts in enumerate(split_evts):\n",
    "    bitstrings = run_hemisphere(invm_evts.reshape(len(invm_evts), -1))\n",
    "    hemisphere_bitstrings[ind] = [\n",
    "        \"\".join(bs) for bs in bitstrings.astype(int).astype(str)\n",
    "    ]\n",
    "\n",
    "hemisphere_eff = (\n",
    "    np.sum(\n",
    "        (hemisphere_bitstrings == CORRECT) | (hemisphere_bitstrings == swap(CORRECT)),\n",
    "        axis=1,\n",
    "    )\n",
    "    / 2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb956ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Invariant mass bins:\", \", \".join([str(invm) for invm in data[0].keys()]))\n",
    "print(\n",
    "    \"Keys:\\n \",\n",
    "    \"\\n  \".join(\n",
    "        [\n",
    "            x\n",
    "            for x in data[0][1.00].keys()\n",
    "            if x not in [\"alphas\", \"betas\", \"gammas\", \"thetas\"]\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c18fa5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# VarQITE Normalization Convergence Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "varqite_data = [\n",
    "    datum\n",
    "    for datum, metadatum in zip(data, metadata)\n",
    "    if metadatum[0] == \"varqite\" and metadatum[2] == \"H2\"\n",
    "]\n",
    "varqite_metadata = [\n",
    "    metadatum\n",
    "    for metadatum in metadata\n",
    "    if metadatum[0] == \"varqite\" and metadatum[2] == \"H2\"\n",
    "]\n",
    "norms = np.array(varqite_metadata)[:, 3]\n",
    "print(\" \" * 7, \" \".join(norms))\n",
    "for invm in INVMS[:-1]:\n",
    "    print(f\"{invm:.2f} -- \", end=\"\")\n",
    "    for datum_param, datum in zip(varqite_metadata, varqite_data):\n",
    "        print(f\"{datum[invm]['evals'].mean():.0f}\", end=\" \")\n",
    "    print()\n",
    "print(\"-\" * 28, \"\\ntotal - \", end=\"\")\n",
    "for datum in varqite_data:\n",
    "    tot_means = np.mean([datum[invm][\"evals\"].mean() for invm in INVMS[:-1]])\n",
    "    print(f\"{tot_means:.0f}\", end=\" \")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "bax = brokenaxes(\n",
    "    ylims=((0, 500), (7750, 8000), (10250, 10500)),\n",
    "    hspace=0.1,\n",
    ")\n",
    "zorders = [10, 1, 9, 3, 4]\n",
    "for datum, norm, zorder in zip(varqite_data, norms, zorders):\n",
    "    evals = np.array([datum[invm][\"evals\"] for invm in INVMS[:-1]]).flatten()\n",
    "    bax.hist(\n",
    "        evals,\n",
    "        bins=100,\n",
    "        histtype=\"stepfilled\",\n",
    "        label=norm.capitalize(),\n",
    "        alpha=0.7,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "\n",
    "bax.set_xlabel(\"Steps used\", labelpad=30)\n",
    "bax.set_ylabel(\"Number of Events\", labelpad=70)\n",
    "bax.set_xlim(0, 500)\n",
    "bax.legend(loc=\"upper left\")\n",
    "bax.grid(axis=\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72610ec0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Efficiency Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6289c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_efficiency_plot(ax):\n",
    "    ax.set_xlim(INVMS[0], INVMS[-1])\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    minor_delta = np.diff(INVMS).min()\n",
    "    ax.set_xticks(INVMS)\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(minor_delta))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.25))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "    ax.set_ylabel(\"Efficiency\")\n",
    "    ax.set_xlabel(\"$m_{tt}/2m_t$\")\n",
    "    ax.grid(which=\"major\", ls=\":\")\n",
    "    ax.set_box_aspect(1)\n",
    "\n",
    "\n",
    "def make_efficiency_plot(ax, efficiency, fill=False, fill_kwargs={}, **kwargs):\n",
    "    X = np.repeat(INVMS, 2)[1:-1]\n",
    "    Y = np.repeat(efficiency, 2)\n",
    "\n",
    "    ax.plot(X, Y, **kwargs)\n",
    "    if fill:\n",
    "        ax.fill_between(X, Y, np.ones_like(Y), **fill_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441cd17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Custom Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba33db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of the other wanted runs\n",
    "etype = \"ttbar\"\n",
    "dtype = \"parton\"\n",
    "infos = [\n",
    "    [\"qaoa\", \"8\", \"max\", etype, dtype],\n",
    "    [\"xqaoa\", \"8\", \"max\", etype, dtype],\n",
    "    [\"maqaoa\", \"8\", \"max\", etype, dtype],\n",
    "    [\"falqon\", \"250\", \"max\", etype, dtype],\n",
    "    [\"varqite\", \"max\", etype, dtype],\n",
    "]\n",
    "inds = parse_with_metadata(infos=infos, metadata=metadata, one_per=False)\n",
    "used_data = data[inds]\n",
    "used_metadata = metadata[inds]\n",
    "# Get efficiencies\n",
    "effs = find_efficiency(data=used_data)\n",
    "# Adding QA efficiencies by hand\n",
    "annealer_eff = [0.014, 0.321, 0.812, 0.930, 0.970, 0.979]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = \"H2\"\n",
    "legend = False\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(9, 9))\n",
    "fig1, ax1 = plt.subplots(figsize=(9, 9))\n",
    "\n",
    "init_efficiency_plot(ax=ax1)\n",
    "init_efficiency_plot(ax=ax2)\n",
    "eff_conf_str, label_buffer = \"\", 15\n",
    "for eff, datum, metadatum in zip(effs, used_data, used_metadata):\n",
    "    if not (metadatum[2] == ham):\n",
    "        continue\n",
    "\n",
    "    color = COLORS[metadatum[0]]\n",
    "    ls = LSS[metadatum[0]]\n",
    "    depth = f\"($p={metadatum[1]}$)\" if metadatum[0] != \"varqite\" else \"\"\n",
    "    label = f\"{LABELS[metadatum[0]]} {depth}\\n$\\\\epsilon={100 * np.mean(eff):.2f}$%\"\n",
    "    make_efficiency_plot(\n",
    "        ax=ax1, efficiency=eff, c=color, lw=4, ls=ls, label=label, zorder=1\n",
    "    )\n",
    "\n",
    "    eff_conf_str += f\"{label.split('-')[0].strip().replace('$', ''):<{label_buffer}} - \"\n",
    "    eff_conf_str += (\n",
    "        \" \".join([f\"{2 * datum[invm]['rank_probs'].mean():.2f}\" for invm in INVMS[:-1]])\n",
    "        + \"\\n\"\n",
    "    )\n",
    "\n",
    "    rank_probs = np.array([datum[invm][\"rank_probs\"].mean() for invm in INVMS[:-1]])\n",
    "    label = f\"{metadatum[0]} {depth} -- {100 * 2 * np.mean(rank_probs):.2f}%\"\n",
    "    make_efficiency_plot(ax=ax2, efficiency=2 * rank_probs, lw=4, label=label)\n",
    "\n",
    "# Plot efficiency for hemisphere method\n",
    "make_efficiency_plot(\n",
    "    ax=ax1,\n",
    "    efficiency=hemisphere_eff,\n",
    "    c=COLORS[\"hemisphere\"],\n",
    "    ls=LSS[\"hemisphere\"],\n",
    "    lw=4,\n",
    "    label=f\"Hemisphere Method\\n$\\\\epsilon={100 * np.mean(hemisphere_eff):.2f}$%\",\n",
    "    zorder=0,\n",
    ")\n",
    "# Plot quantum annealer data\n",
    "make_efficiency_plot(\n",
    "    ax=ax1,\n",
    "    efficiency=annealer_eff,\n",
    "    c=COLORS[\"annealer\"],\n",
    "    ls=LSS[\"annealer\"],\n",
    "    lw=4,\n",
    "    label=f\"Quantum Annealer\\n$\\\\epsilon={100 * np.mean(annealer_eff):.2f}$%\",\n",
    "    zorder=0,\n",
    ")\n",
    "\n",
    "buffer = max([len(x.split(\"- \")[0]) for x in eff_conf_str.split(\"\\n\")]) + 2\n",
    "print(\" \" * buffer + \" \".join([f\"{invm:.2f}\" for invm in INVMS[:-1]]))\n",
    "print(eff_conf_str)\n",
    "\n",
    "make_efficiency_plot(\n",
    "    ax=ax1,\n",
    "    efficiency=bruteforce_dict[ham],\n",
    "    color=FILL_KWARGS[\"color\"],\n",
    "    zorder=0,\n",
    "    fill=True,\n",
    "    fill_kwargs=FILL_KWARGS,\n",
    ")\n",
    "ax1.set_title(rf\"Hamiltonian ${'_'.join(list(ham))}$\")\n",
    "ax2.set_ylabel(\"Average probability\")\n",
    "ax2.set_title(rf\"Mean Probabilities for Hamiltonian: ${'_'.join(list(ham))}$\")\n",
    "# ax1.text(2.51, 0.02, \"Smeared Events\", fontsize=14)\n",
    "\n",
    "if legend:\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax2.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d059b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []\n",
    "for metadatum, eff in zip(used_metadata, effs):\n",
    "    if metadatum[2] != ham:\n",
    "        continue\n",
    "\n",
    "    depth = f\"($p={metadatum[1]}$)\" if metadatum[0] != \"varqite\" else \"\"\n",
    "    label = f\"{LABELS[metadatum[0]]} {depth}\\n$\\\\epsilon={100 * np.mean(eff):.2f}$%\"\n",
    "    color = COLORS[metadatum[0]]\n",
    "    ls = LSS[metadatum[0]]\n",
    "    lw = 4\n",
    "    handles.append(Line2D([0], [0], label=label, color=color, ls=ls, lw=lw))\n",
    "\n",
    "handles.append(\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        label=f\"{LABELS['hemisphere']}\\n$\\\\epsilon={100 * np.mean(hemisphere_eff):.2f}$%\",\n",
    "        color=COLORS[\"hemisphere\"],\n",
    "        ls=LSS[\"hemisphere\"],\n",
    "        lw=lw,\n",
    "    )\n",
    ")\n",
    "# handles.append(\n",
    "#     Line2D(\n",
    "#         [0],\n",
    "#         [0],\n",
    "#         label=f\"{LABELS['annealer']}\\n$\\\\epsilon={100 * np.mean(annealer_eff):.2f}$%\",\n",
    "#         color=COLORS[\"annealer\"],\n",
    "#         ls=LSS[\"annealer\"],\n",
    "#         lw=lw,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "fig = plt.figure()\n",
    "leg = fig.legend(handles=handles, loc=\"center\", handlelength=4, ncols=7)\n",
    "fig.patch.set_visible(False)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448ec54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## FALQON Depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60592e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = \"H2\"\n",
    "depths = [25, 50, 100, 250, 500, 1000, 1500, 2000, 2500]\n",
    "infos = [[\"falqon\", \"ttbar\", \"parton\", ham, str(depth)] for depth in depths]\n",
    "falqon_inds = parse_with_metadata(infos, metadata=metadata)\n",
    "falqon_data = data[falqon_inds]\n",
    "falqon_metadata = metadata[falqon_inds]\n",
    "falqon_effs = find_efficiency(data=falqon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ec588",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(9, 9))\n",
    "fig1, ax1 = plt.subplots(figsize=(9, 9))\n",
    "\n",
    "init_efficiency_plot(ax=ax1)\n",
    "init_efficiency_plot(ax=ax2)\n",
    "eff_conf_str, label_buffer = \"\", 15\n",
    "for eff, datum, metadatum in zip(falqon_effs, falqon_data, falqon_metadata):\n",
    "    ls = \"solid\"\n",
    "    label = f\"[$p={metadatum[1]}$] -- {100 * np.mean(eff):.2f}%\"\n",
    "    make_efficiency_plot(ax=ax1, efficiency=eff, ls=ls, lw=4, label=label)\n",
    "\n",
    "    eff_conf_str += f\"{label.split('-')[0].strip().replace('$', ''):<{label_buffer}} - \"\n",
    "    eff_conf_str += (\n",
    "        \" \".join([f\"{2 * datum[invm]['rank_probs'].mean():.2f}\" for invm in INVMS[:-1]])\n",
    "        + \"\\n\"\n",
    "    )\n",
    "    rank_probs = np.array([datum[invm][\"rank_probs\"].mean() for invm in INVMS[:-1]])\n",
    "    label = f\"[$p={metadatum[1]}$] -- {100 * 2 * np.mean(rank_probs):.2f}%\"\n",
    "    make_efficiency_plot(ax=ax2, efficiency=2 * rank_probs, ls=ls, lw=4, label=label)\n",
    "\n",
    "buffer = max([len(x.split(\"- \")[0]) for x in eff_conf_str.split(\"\\n\")]) + 2\n",
    "print(\" \" * buffer + \" \".join([f\"{invm:.2f}\" for invm in INVMS[:-1]]))\n",
    "print(eff_conf_str)\n",
    "\n",
    "fill_kwargs = {\"color\": \"#23578923\", \"hatch\": \"x\"}\n",
    "make_efficiency_plot(\n",
    "    ax=ax1,\n",
    "    efficiency=bruteforce_dict[ham],\n",
    "    color=\"#235789\",\n",
    "    fill=True,\n",
    "    fill_kwargs=fill_kwargs,\n",
    ")\n",
    "ax1.set_title(rf\"Efficiency for ${'_'.join(list(ham))}$\")\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax2.set_ylabel(\"Average probability\")\n",
    "ax2.set_title(r\"Mean Probabilities for $H_2$\")\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a1fdb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Mass Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f937c",
   "metadata": {},
   "source": [
    "## 2-Dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2dhist_mass(masses, etype, bins=250, lims=(0, 500), m_6jet=0):\n",
    "    # Mask the masses to get constant sized bins on plot\n",
    "    lim_mask = ((masses > lims[0]) & (masses < lims[1])).all(axis=1)\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    ax_cbar = divider.append_axes(\"right\", size=\"5%\", pad=0.15)\n",
    "    fig.add_axes(ax_cbar)\n",
    "\n",
    "    _, _, _, img = ax.hist2d(\n",
    "        *masses[lim_mask].T,\n",
    "        bins=bins,\n",
    "        norm=LogNorm(vmin=1, vmax=1e3),\n",
    "        cmap=\"RdPu\",\n",
    "        range=(lims, lims),\n",
    "    )\n",
    "    cbar = fig.colorbar(img, cax=ax_cbar)\n",
    "    cbar.set_label(\"Counts\", rotation=270, labelpad=15)\n",
    "\n",
    "    yaxis_mass = {\"tW\": W_MASS, \"ttbar\": TOP_MASS, \"6jet\": m_6jet}[etype]\n",
    "    yaxis_label = {\"tW\": \"m_W\", \"ttbar\": \"m_t\", \"6jet\": \"m\"}[etype]\n",
    "    xaxis_mass = {\"tW\": TOP_MASS, \"ttbar\": TOP_MASS, \"6jet\": m_6jet}[etype]\n",
    "    xaxis_label = {\"tW\": \"m_t\", \"ttbar\": \"m_t\", \"6jet\": \"m\"}[etype]\n",
    "    origin = {\n",
    "        \"tW\": [TOP_MASS, W_MASS],\n",
    "        \"ttbar\": [TOP_MASS, TOP_MASS],\n",
    "        \"6jet\": [m_6jet, m_6jet],\n",
    "    }[etype]\n",
    "    ax.axvline(xaxis_mass, c=\"k\", ls=\":\", alpha=0.4, zorder=10)\n",
    "    ax.axhline(yaxis_mass, c=\"k\", ls=\":\", alpha=0.4, zorder=10)\n",
    "\n",
    "    ax.set_ylabel(f\"${yaxis_label}$ (GeV)\")\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(50))\n",
    "    ax.set_xlabel(f\"${xaxis_label}$ (GeV)\")\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(50))\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    fracs = [0.8, 0.9, 0.99]\n",
    "    lss = [(0, (1, 1)), (0, (5, 5)), \"solid\"]\n",
    "    alpha = \"aa\"\n",
    "    colors = [f\"#8642A8{alpha}\", f\"#8642A8{alpha}\", f\"#8642A8{alpha}\"]\n",
    "    for frac, ls, color in zip(fracs, lss, colors):\n",
    "        distances = np.sqrt(np.sum((masses - origin) ** 2, axis=1))\n",
    "        sorted_distances = np.sort(distances)\n",
    "        thresh = sorted_distances[int(frac * len(sorted_distances))]\n",
    "        circle = plt.Circle(origin, thresh, ec=color, ls=ls, fc=\"#00000000\", lw=2)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    handles = [\n",
    "        Line2D([0], [0], ls=ls, label=f\"{100 * frac:.0f}%\", c=c)\n",
    "        for ls, c, frac in zip(lss, colors, fracs)\n",
    "    ]\n",
    "    ax.legend(handles=handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b521c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = [\"xqaoa\", \"8\", \"max\", \"H2\", \"ttbar\", \"smeared\"]\n",
    "ind = parse_with_metadata(infos=[info], metadata=metadata)[0]\n",
    "masses = get_2dhist_invms(data[ind], metadata[ind])\n",
    "print(metadata[ind])\n",
    "if metadata[ind][4] != \"6jet\":\n",
    "    print(f\"Efficiency: {100 * np.mean(find_efficiency(data=[data[ind]])):.2f}%\")\n",
    "plot_2dhist_mass(masses, bins=300, lims=(0, 500), etype=metadata[ind][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `evts` is defined by etype and dtype at the very beginning\n",
    "masses = get_bitstring_invms(evts, bitstrings=CORRECT)\n",
    "print(\"correct bitstring\")\n",
    "plot_2dhist_mass(masses, lims=(0, 500), etype=evts_etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4dd62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = \"H2\"\n",
    "min_bitstrings = get_minimum_energies(evts=evts, hamiltonian=ham)[:, 0].astype(\"S6\")\n",
    "masses = get_bitstring_invms(evts=evts, bitstrings=min_bitstrings)\n",
    "print(f\"{ham} Hamiltonian\")\n",
    "print(\n",
    "    f\"Efficiency: {100 * np.sum(min_bitstrings.astype('U6') == CORRECT) / len(min_bitstrings):.2f}%\"\n",
    ")\n",
    "plot_2dhist_mass(masses, lims=(0, 500), etype=metadata[ind][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c49650",
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = get_bitstring_invms(\n",
    "    evts=evts, bitstrings=hemisphere_bitstrings.astype(\"S6\").flatten()\n",
    ")\n",
    "print(\"Hemisphere method\")\n",
    "print(\n",
    "    f\"Efficiency: {np.sum(np.logical_or(hemisphere_bitstrings == CORRECT, hemisphere_bitstrings == swap(CORRECT))) / len(hemisphere_bitstrings.flatten()):.2f}\"\n",
    ")\n",
    "plot_2dhist_mass(masses, lims=(0, 500), etype=metadata[ind][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4929533f",
   "metadata": {},
   "source": [
    "## 1-Dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = \"H0\"\n",
    "algs = [\"qaoa\", \"maqaoa\", \"xqaoa\", \"varqite\"]\n",
    "infos = [\n",
    "    [\"maqaoa\", \"max\", ham, \"8\", \"parton\"],\n",
    "    [\"varqite\", \"max\", ham, \"parton\"],\n",
    "    [\"falqon\", \"max\", ham, \"250\", \"parton\"],\n",
    "    [\"xqaoa\", \"max\", ham, \"8\", \"parton\"],\n",
    "    [\"qaoa\", \"max\", ham, \"8\", \"parton\"],\n",
    "]\n",
    "inds = parse_with_metadata(infos=infos, metadata=metadata)\n",
    "all_masses = np.array([get_2dhist_invms(data[ind], metadata[ind]) for ind in inds])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "# This will make sure they all have the same mass bin width\n",
    "bins = np.histogram(np.hstack(all_masses), bins=1000)[1]\n",
    "# This centers the bins on the TOP_MASS, looks nice :)\n",
    "bins -= (bins[np.searchsorted(bins, TOP_MASS)] - TOP_MASS) + (bins[1] - bins[0]) / 2\n",
    "handles = []\n",
    "for masses, info in zip(all_masses, infos):\n",
    "    ax.hist(masses.flatten(), histtype=\"step\", bins=bins, color=COLORS[info[0]])\n",
    "    depth_label = \"\" if not info[3].isdigit() else f\" ($p={info[3]}$)\"\n",
    "    label = f\"{LABELS[info[0]]}{depth_label}\"\n",
    "    handles.append(Patch(label=label, color=COLORS[info[0]]))\n",
    "ax.axvline(TOP_MASS, c=\"k\", ls=\":\", alpha=0.4, zorder=10)\n",
    "\n",
    "diff = 10\n",
    "ax.set_xlim(TOP_MASS - diff, TOP_MASS + diff)\n",
    "ax.set_xlabel(\"$m_t$ (GeV)\")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.legend(handles=handles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ac78fb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Number of Jets Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064db1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_numjets(jet_vals, jet_counts, num_fsp):\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "    bar = ax.bar(jet_vals, jet_counts / jet_counts.sum(), width=0.8, color=\"#7b3e19\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "    ax.set_xlim(-0.5, num_fsp + 0.5)\n",
    "    ax.set_xlabel(\"Number of Jets\")\n",
    "\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel(\"Fraction of Events\")\n",
    "    ax.tick_params(axis=\"y\", right=True)\n",
    "    ax.grid(axis=\"y\", alpha=0.4)\n",
    "\n",
    "    ax.bar_label(bar, fmt=\"{:.3f}\")\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_box_aspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479cd4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = [\"falqon\", \"250\", \"H2\", \"max\", \"ttbar\", \"parton\"]\n",
    "ind = parse_with_metadata([info], metadata=metadata)[0]\n",
    "datum = data[ind]\n",
    "bitstrings = get_bitstrings(datum)\n",
    "num_fsp = len(bitstrings[0][0])\n",
    "num_jets0 = np.char.count(bitstrings, \"0\").flatten()\n",
    "num_jets1 = np.char.count(bitstrings, \"1\").flatten()\n",
    "jet_vals, jet_counts = np.unique(\n",
    "    np.concatenate((num_jets0, num_jets1)), return_counts=True\n",
    ")\n",
    "\n",
    "print(metadata[ind])\n",
    "plot_hist_numjets(jet_vals, jet_counts, num_fsp=num_fsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = \"H2\"\n",
    "bitstrings = get_minimum_energies(evts=evts, hamiltonian=ham)[:, 0].astype(str)\n",
    "num_fsp = len(bitstrings[0])\n",
    "num_jets0 = np.char.count(bitstrings, \"0\").flatten()\n",
    "num_jets1 = np.char.count(bitstrings, \"1\").flatten()\n",
    "jet_vals, jet_counts = np.unique(\n",
    "    np.concatenate((num_jets0, num_jets1)), return_counts=True\n",
    ")\n",
    "\n",
    "print(f\"Hamiltonian: {ham}\")\n",
    "plot_hist_numjets(jet_vals, jet_counts, num_fsp=num_fsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fsp = len(hemisphere_bitstrings[0][0])\n",
    "num_jets0 = np.char.count(hemisphere_bitstrings, \"0\").flatten()\n",
    "num_jets1 = np.char.count(hemisphere_bitstrings, \"1\").flatten()\n",
    "jet_vals, jet_counts = np.unique(\n",
    "    np.concatenate((num_jets0, num_jets1)), return_counts=True\n",
    ")\n",
    "\n",
    "plot_hist_numjets(jet_vals, jet_counts, num_fsp=num_fsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1174071",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Efficiency vs Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = \"H2\"\n",
    "depths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 25]\n",
    "algs = [\"qaoa\", \"maqaoa\", \"xqaoa\"]\n",
    "# Get all depths for the given algorithsm\n",
    "infos = np.array(\n",
    "    [[[alg, depth, \"max\", ham, \"ttbar\", \"parton\"] for depth in depths] for alg in algs]\n",
    ").reshape(len(algs) * len(depths), -1)\n",
    "# Get their indices and find the efficiencies\n",
    "inds = parse_with_metadata(infos=infos, metadata=metadata)\n",
    "correct_effs = np.mean(find_efficiency(data=data[inds]), axis=1).reshape(len(algs), -1)\n",
    "min_effs = np.mean(find_efficiency(data=data[inds], find_correct=False), axis=1).reshape(\n",
    "    len(algs), -1\n",
    ")\n",
    "# Get best case for correct efficiency\n",
    "min_bitstrings = get_minimum_energies(evts=evts, hamiltonian=ham)[:, 0]\n",
    "ham_limit_eff = np.sum(min_bitstrings == CORRECT) / len(min_bitstrings)\n",
    "# Get VarQITE values\n",
    "varqite_datum = data[\n",
    "    parse_with_metadata(infos=[[\"varqite\", \"max\", \"H2\", \"parton\"]], metadata=metadata)\n",
    "]\n",
    "varqite_correct = np.mean(find_efficiency(data=varqite_datum))\n",
    "varqite_min = np.mean(find_efficiency(data=varqite_datum, find_correct=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89213999",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Plots algs\n",
    "for alg, correct_eff, min_eff in zip(algs, correct_effs, min_effs):\n",
    "    color = COLORS[alg]\n",
    "    ax.plot(depths, correct_eff, marker=\"o\", ls=\"dotted\", c=color)\n",
    "    ax.plot(depths, min_eff, marker=\"o\", ls=\"solid\", c=color)\n",
    "\n",
    "# Plot VarQITE\n",
    "ax.axhline(varqite_correct, ls=\"dotted\", c=COLORS[\"varqite\"], lw=3)\n",
    "ax.axhline(varqite_min, ls=\"solid\", c=COLORS[\"varqite\"], lw=3)\n",
    "\n",
    "# Plot Hamiltonian limit\n",
    "xlim = [depths[0] - 0.5, depths[-1] + 0.5]\n",
    "ax.fill_between(xlim, ham_limit_eff, 1, **FILL_KWARGS)\n",
    "ax.axhline(ham_limit_eff, c=FILL_KWARGS[\"color\"], alpha=0.8, lw=2, zorder=0)\n",
    "\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.set_xticks(depths)\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_xlabel(\"Depth $p$\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel(\"Success Rate\")\n",
    "ax.grid(axis=\"y\")\n",
    "ax.grid(axis=\"y\", which=\"minor\", ls=\"dotted\")\n",
    "\n",
    "eff_handles = [\n",
    "    Line2D([0], [0], ls=\"solid\", label=\"Minimum\", color=\"k\"),\n",
    "    Line2D([0], [0], ls=\"dotted\", label=\"Correct\", color=\"k\"),\n",
    "]\n",
    "eff_leg = ax.legend(\n",
    "    handles=eff_handles,\n",
    "    bbox_to_anchor=(0.840, 0),\n",
    "    loc=\"lower right\",\n",
    "    title=\"Efficiency Type\",\n",
    ")\n",
    "ax.add_artist(eff_leg)\n",
    "\n",
    "alg_handles = [Patch(color=COLORS[alg], label=LABELS[alg]) for alg in algs + [\"varqite\"]]\n",
    "ax.legend(handles=alg_handles, title=\"Algorithm\", loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc3c75",
   "metadata": {},
   "source": [
    "## FALQON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc322cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full info of FALQON run\n",
    "ham = \"H2\"\n",
    "etype = \"ttbar\"\n",
    "num_evts = 2000\n",
    "full_falqon_data = load_data(\n",
    "    alg=\"falqon\",\n",
    "    depth=2500,\n",
    "    hamiltonian=ham,\n",
    "    norm=\"max\",\n",
    "    etype=etype,\n",
    "    dtype=\"parton\",\n",
    "    lambda_nume=\"minJij\",\n",
    "    lambda_denom=\"maxPij\",\n",
    "    num_evts=num_evts,\n",
    ")\n",
    "# Additional info\n",
    "cor_bs = SYM_TRUE_BS_DICT[etype]\n",
    "num_fsp = NUM_FSP_DICT[etype]\n",
    "bitstrings = np.array([format(x, f\"0{num_fsp}b\") for x in range(2**num_fsp)])\n",
    "min_bitstrings = get_minimum_energies(evts=evts, hamiltonian=ham)[:, 0]\n",
    "ham_limit_eff = np.sum(min_bitstrings == CORRECT) / len(min_bitstrings)\n",
    "\n",
    "eff_cor_depth = np.zeros(2500)\n",
    "eff_min_depth = np.zeros(2500)\n",
    "# Iterate over invariant masses and get efficiencies\n",
    "for invm in INVMS[:-1]:\n",
    "    # Find order of probabilities by index\n",
    "    prob_ordered_inds = np.flip(\n",
    "        np.argsort(full_falqon_data[invm][\"depth_probs\"], axis=2), axis=2\n",
    "    )\n",
    "    # Get minimum bitstring for each event, cast to correct array shape\n",
    "    min_bs = get_minimum_energies(\n",
    "        evts=full_falqon_data[invm][\"invm_p4s\"], hamiltonian=ham\n",
    "    )[:, 0][:, None, None]\n",
    "    # Find where bitstring of importance is\n",
    "    ranks_cor = np.argmax(bitstrings[prob_ordered_inds] == cor_bs, axis=-1)\n",
    "    ranks_min = np.argmax(bitstrings[prob_ordered_inds] == min_bs, axis=-1)\n",
    "    # Assume symmetry\n",
    "    ranks_cor -= ranks_cor % 2\n",
    "    ranks_min -= ranks_min % 2\n",
    "    # And find if it ranks first\n",
    "    eff_cor_depth += np.count_nonzero(ranks_cor == 0, axis=0)\n",
    "    eff_min_depth += np.count_nonzero(ranks_min == 0, axis=0)\n",
    "# Free up RAM\n",
    "del full_falqon_data\n",
    "# Normalize\n",
    "tot_num_evts = int(num_evts) * (len(INVMS) - 1)\n",
    "eff_cor_depth /= tot_num_evts\n",
    "eff_min_depth /= tot_num_evts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "xlim = [10, 2500]\n",
    "ax.fill_between(xlim, ham_limit_eff, 1, **FILL_KWARGS)\n",
    "ax.axhline(ham_limit_eff, c=FILL_KWARGS[\"color\"], alpha=0.8, lw=2, zorder=0)\n",
    "\n",
    "ax.plot(eff_cor_depth, c=\"#48156F\", lw=4, label=\"Correct\")\n",
    "ax.plot(eff_min_depth, c=\"#2DABAF\", ls=\"dashed\", lw=4, label=\"Minimum\")\n",
    "ax.plot(ham_limit_eff * eff_min_depth, c=\"k\", lw=4, alpha=0.2, label=\"Perfect\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel(\"Efficiency\")\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_xlabel(\"Depth $p$\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.grid(axis=\"x\", which=\"major\")\n",
    "ax.grid(axis=\"x\", which=\"minor\", ls=\"dotted\")\n",
    "ax.grid(axis=\"y\", which=\"major\")\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94367b02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exploring $\\lambda_2$\n",
    "If we write $H_2=H_0 + \\dfrac{\\lambda}{2\\lambda_2}H_1$, then $\\lambda_2$ acts as a scaling factor that shifts between $H_0$ and $H_1$, with $\\lambda_2=1$ giving $H_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d682162",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lmbdas = 120\n",
    "min_lambda2, max_lambda2 = 10**-4, 10**6\n",
    "lambda2s = np.geomspace(min_lambda2, max_lambda2, num_lmbdas)\n",
    "\n",
    "# Find efficiency of Hamiltonian for different values of lambda2\n",
    "effs = []\n",
    "for invm_evts in split_evts:\n",
    "    invm_effs = []\n",
    "    for lambda2 in lambda2s:\n",
    "        min_bitstrings = get_minimum_energies(\n",
    "            evts=invm_evts, hamiltonian=\"H2\", scale=1 / lambda2\n",
    "        )[:, 0]\n",
    "        invm_effs.append(np.sum(min_bitstrings == CORRECT) / len(min_bitstrings))\n",
    "    effs.append(invm_effs)\n",
    "effs = np.array(effs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ca43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "lambda_label = r\"\\lambda=\\min(J_{ij})/\\max(P_{ij})\"\n",
    "colors = multifader(\n",
    "    colors=[\"#5D2E46\", \"#E53D00\"], fractions=np.linspace(0, 1, len(INVMS) - 1)\n",
    ")\n",
    "for invm_effs, color, invm_lo, invm_hi in zip(effs, colors, INVMS[:-1], INVMS[1:]):\n",
    "    label = f\"${invm_lo:.2f}<m_{{tt}}/2m_t<{invm_hi:.2f}$\"\n",
    "    # ax.scatter(lambda2s, invm_effs, c=color)\n",
    "    ax.plot(lambda2s, invm_effs, c=color, label=label)\n",
    "\n",
    "ax.plot(\n",
    "    lambda2s,\n",
    "    effs.mean(axis=0),\n",
    "    c=\"k\",\n",
    "    alpha=0.7,\n",
    "    ls=(5, (10, 3)),\n",
    "    lw=4,\n",
    "    label=\"Total\",\n",
    "    dash_capstyle=\"round\",\n",
    ")\n",
    "max_ind = effs.mean(axis=0).argmax()\n",
    "max_eff_lambda2 = lambda2s[max_ind]\n",
    "max_eff = effs.mean(axis=0)[max_ind]\n",
    "ax.axvline(max_eff_lambda2, c=\"k\", ls=\"dotted\", alpha=0.5)\n",
    "ax.axhline(max_eff, c=\"k\", ls=\"dotted\", alpha=0.5)\n",
    "val, power = f\"{max_eff_lambda2:.3e}\".split(\"e+\")\n",
    "v = rf\"{val}x10^{{{int(power)}}}\"\n",
    "ax.annotate(\n",
    "    \"Optimal\\n\" + rf\"$\\lambda_2={v}$\" + \"\\n\" + rf\"$\\epsilon={max_eff:.2f}$\",\n",
    "    xy=(max_eff_lambda2, max_eff),\n",
    "    xytext=(max_eff_lambda2 / 8.5, max_eff / 1.3),\n",
    "    ha=\"center\",\n",
    "    arrowprops={\"fc\": \"black\", \"shrink\": 0.05},\n",
    "    bbox={\"boxstyle\": \"round\", \"fc\": \"white\"},\n",
    ")\n",
    "\n",
    "ax.axvline(1, c=\"k\", lw=4, zorder=0)\n",
    "ax.text(\n",
    "    s=\"$H_2$\",\n",
    "    x=1.3,\n",
    "    y=0.55,\n",
    "    fontsize=15,\n",
    "    bbox={\"boxstyle\": \"round\", \"fc\": \"#dddddd\"},\n",
    ")\n",
    "right = dict(boxstyle=\"rarrow,pad=0.3\", fc=\"#dddddd\", lw=2)\n",
    "left = dict(boxstyle=\"larrow,pad=0.3\", fc=\"#dddddd\", lw=2)\n",
    "ax.text(\n",
    "    0.88,\n",
    "    0.55,\n",
    "    f\"{' ' * 6}$H_0${' ' * 6}\",\n",
    "    size=15,\n",
    "    bbox=right,\n",
    "    transform=ax.transAxes,\n",
    ")\n",
    "ax.text(\n",
    "    0.04,\n",
    "    0.55,\n",
    "    f\"{' ' * 6}$H_1${' ' * 6}\",\n",
    "    size=15,\n",
    "    bbox=left,\n",
    "    transform=ax.transAxes,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Efficiency\", fontsize=15)\n",
    "ax.set_ylim(0, 1.02)\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "ax.set_xscale(\"log\")\n",
    "ax.xaxis.set_major_locator(LogLocator(numticks=10))\n",
    "ax.xaxis.set_minor_locator(LogLocator(numticks=1000, subs=\"auto\"))\n",
    "ax.set_xlim(0.95 * min_lambda2, 1.05 * max_lambda2)\n",
    "ax.set_xlabel(r\"$\\lambda_2$\", fontsize=15)\n",
    "ax.set_title(f\"{evts_dtype.capitalize()} events, ${lambda_label}$\", fontsize=18)\n",
    "ax.grid(alpha=0.6)\n",
    "ax.grid(which=\"minor\", alpha=0.6, ls=\"dotted\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_evts = get_data(\"ttbar\", \"parton\")[0]\n",
    "split_comp_evts = split_data(comp_evts)[0]\n",
    "eff_types = [\n",
    "    [\"H2\", \"$H_2$\", {}],\n",
    "    [\"H2\", \"$H_2$ optimal\", {\"scale\": 1 / max_eff_lambda2}],\n",
    "    [\"H2\", \"$H_2$ not so optimal\", {\"scale\": 1 / 100}],\n",
    "    [\"H0\", \"$H_0$\", {}],\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "init_efficiency_plot(ax)\n",
    "for ham, label, kwargs in eff_types:\n",
    "    effs = []\n",
    "    for cevts in split_comp_evts:\n",
    "        effs.append(\n",
    "            (\n",
    "                get_minimum_energies(cevts, hamiltonian=ham, **kwargs)[:, 0] == CORRECT\n",
    "            ).sum()\n",
    "            / len(cevts)\n",
    "        )\n",
    "\n",
    "    make_efficiency_plot(\n",
    "        ax=ax, efficiency=effs, lw=4, label=f\"{label} - {100 * np.mean(effs):.2f}%\"\n",
    "    )\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b9b93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Per Event VarQITE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = get_coefficients(\n",
    "    hamiltonian=\"H2\", evts=evts, nume=[\"min\", \"Jij\"], denom=[\"max\", \"Pij\"]\n",
    ")[split_inds]\n",
    "min_energies = get_minimum_energies(\n",
    "    hamiltonian=\"H2\", evts=evts, nume=[\"min\", \"Jij\"], denom=[\"max\", \"Pij\"]\n",
    ")[split_inds]\n",
    "all_energies = get_all_bitstring_energies(\n",
    "    evts=evts, hamiltonian=\"H2\", nume=[\"min\", \"Jij\"], denom=[\"max\", \"Pij\"]\n",
    ")[1][split_inds]\n",
    "\n",
    "# 0 -- 1.00 | 1 -- 1.25 | 2 -- 1.50\n",
    "# 3 -- 1.75 | 4 -- 2.00 | 5 -- 2.50\n",
    "invm_bin = 2\n",
    "N = 0\n",
    "\n",
    "coeff = coeffs[invm_bin][N] / coeffs[invm_bin][N].max()\n",
    "min_energy = min_energies[invm_bin][N]\n",
    "all_energy = all_energies[invm_bin][N]\n",
    "bitstring_energies = all_energies[invm_bin][N]\n",
    "invm = invms[split_inds][invm_bin][N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc9190",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimum bitstring: {min_energy[0]} -- {min_energy[1]:+.3e}\")\n",
    "\n",
    "varqite = VarQITE(coeff=coeff, dtau=0.5, steps=500, prec=1e-5, device=\"lightning.gpu\")\n",
    "varqite.optimize(steps_till_newline=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_bs = \"000111\"\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "probs = varqite.get_probs()\n",
    "probs_plot = probs\n",
    "bar = bar_count(\n",
    "    ax=ax,\n",
    "    counts=probs_plot,\n",
    "    sort_type=\"desc\",\n",
    "    bar_params={\"color\": \"#333355\"},\n",
    "    x_rot=90,\n",
    ")\n",
    "ax.set_ylabel(\"Probability\")\n",
    "red_inds = np.unique(\n",
    "    np.append(\n",
    "        np.where(bar.datavalues == probs_plot[correct_bs]),\n",
    "        np.where(bar.datavalues == probs_plot.get(swap(correct_bs))),\n",
    "    )\n",
    ")\n",
    "green_inds = np.unique(\n",
    "    np.append(\n",
    "        np.where(bar.datavalues == probs_plot[min_energy[0]]),\n",
    "        np.where(bar.datavalues == probs_plot.get(swap(min_energy[0]))),\n",
    "    )\n",
    ")\n",
    "for red_ind, green_ind in zip(red_inds, green_inds):\n",
    "    if red_ind == green_ind:\n",
    "        bar[red_ind].set_color(\"#D0DE9C\")\n",
    "    else:\n",
    "        bar[red_ind].set_color(\"#CB1616\")\n",
    "        bar[green_ind].set_color(\"#16DB93\")\n",
    "\n",
    "ax.annotate(\n",
    "    text=f\"Minimum bitstring: {min_energy[0]}\\nInvariant mass: {invm:.2f}\",\n",
    "    xy=(0.8, 0.9),\n",
    "    xycoords=\"axes fraction\",\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"#99a7cb\"),\n",
    ")\n",
    "# ax.set_yscale(\"log\")\n",
    "\n",
    "eng_ax = ax.twinx()\n",
    "# Plot the energy for each bitstring\n",
    "all_energy_dict = dict(zip(varqite.bitstrings.tolist(), all_energy.tolist()))\n",
    "prob_energies = (\n",
    "    np.array([all_energy_dict[t.get_text()] for t in ax.get_xticklabels()]) / 1e9\n",
    ")\n",
    "num_x = len(prob_energies)\n",
    "xrange = np.arange(num_x)\n",
    "\n",
    "\n",
    "# fit energies to a quadratic\n",
    "def fit(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "\n",
    "params = curve_fit(f=fit, xdata=xrange, ydata=prob_energies)[0]\n",
    "eng_diff = abs(prob_energies.max() - prob_energies.min())\n",
    "x_fit = np.linspace(-0.6, num_x, 100)\n",
    "y_fit = fit(x_fit, *params)\n",
    "\n",
    "eng_ax.plot(prob_energies, c=\"k\", ls=\"dashed\", alpha=0.3)\n",
    "eng_ax.plot(\n",
    "    xrange[prob_energies > 0],\n",
    "    prob_energies[prob_energies > 0],\n",
    "    marker=\"d\",\n",
    "    lw=0,\n",
    "    markerfacecolor=\"none\",\n",
    "    markeredgecolor=\"k\",\n",
    "    markeredgewidth=1.5,\n",
    ")\n",
    "eng_ax.plot(\n",
    "    xrange[prob_energies < 0],\n",
    "    prob_energies[prob_energies < 0],\n",
    "    marker=\"d\",\n",
    "    lw=0,\n",
    "    color=\"k\",\n",
    ")\n",
    "eng_ax.plot(x_fit, y_fit, c=\"#83a18f\", alpha=0.7, lw=5, zorder=0)\n",
    "eng_ax.set_ylabel(\"Energy [GeV]\")\n",
    "eng_ax.axhline(0, ls=\"dotted\", alpha=0.1, c=\"k\")\n",
    "eng_ax.set_ylim(\n",
    "    prob_energies.min() - 0.10 * eng_diff, prob_energies.max() + 0.10 * eng_diff\n",
    ")\n",
    "eng_ax.fill_between(x=x_fit, y1=0, y2=eng_ax.get_ylim()[0], color=\"k\", alpha=0.1)\n",
    "ax.set_xlim(-0.6, num_x - 0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "all_probs = np.array(\n",
    "    [list(varqite.get_probs(thetas).values()) for thetas in varqite.all_thetas]\n",
    ")\n",
    "for ind, probs in enumerate(all_probs.T):\n",
    "    bitstring = format(ind, f\"0{varqite.nq}b\")\n",
    "    ls = \"solid\" if bitstring in [correct_bs, swap(correct_bs)] else \"dotted\"\n",
    "    ax.plot(probs, ls=ls)\n",
    "ax.set_title(\"Probabilities per step\")\n",
    "ax.set_xlim(0, varqite.total_steps - 1)\n",
    "ax.set_xlabel(\"steps\")\n",
    "ax.set_ylim(0, 0.5)\n",
    "ax.set_ylabel(\"probability\")\n",
    "# ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "ax.plot(varqite.energy_diffs, c=\"k\", label=r\"$\\Delta E$\")\n",
    "ax.plot(\n",
    "    np.abs(varqite.energy_diffs / varqite.energies[1:]),\n",
    "    c=\"#b9a0b1\",\n",
    "    label=r\"$\\Delta E / E$\",\n",
    ")\n",
    "ax.axhline(varqite.prec, c=\"#b9a0b1\", ls=\"dashed\", label=\"Precision limit\")\n",
    "ax.set_xlim(0, varqite.total_steps - 2)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"steps\")\n",
    "ax.set_title(r\"$\\Delta E$ per step\")\n",
    "ax.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ab80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "min_energy = min(varqite.energies.min(), varqite.op_energies.min())\n",
    "\n",
    "for op_energies in varqite.op_energies.T:\n",
    "    ax.plot(op_energies - min_energy, ls=\"dotted\")\n",
    "ax.plot(varqite.energies - min_energy, c=\"k\", lw=2)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Normalized energy\")\n",
    "ax.axhline(-min_energy, c=\"k\", alpha=0.2)\n",
    "ax.set_xlim(0, varqite.total_steps - 1)\n",
    "ax.set_xlabel(\"steps\")\n",
    "ax.set_title(\"Energies per step\")\n",
    "\n",
    "# ax2 = ax.twinx()\n",
    "# ax2.plot(varqite.energies - varqite.energies.min(), c=\"r\", ls=\"dashed\")\n",
    "# ax2.set_yscale(\"log\")\n",
    "handles = [\n",
    "    # Line2D([0], [0], c=\"none\", label=\"Left Axis\"),\n",
    "    Line2D([0], [0], ls=\"dotted\", c=\"k\", label=\"Pauli-$Z$ strings\"),\n",
    "    Line2D([0], [0], ls=\"solid\", c=\"k\", label=\"Hamiltonian\"),\n",
    "    Line2D([0], [0], ls=\"solid\", c=\"k\", alpha=0.2, label=\"Shifted zero energy\"),\n",
    "    # Line2D([0], [0], c=\"none\", label=\"Right Axis\"),\n",
    "    # Line2D([0], [0], ls=\"dashed\", c=\"r\", label=\"Hamiltonian\"),\n",
    "]\n",
    "ax.legend(handles=handles, loc=\"lower left\")  # , ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_formatter(x, pos):\n",
    "    frac = Fraction(x / np.pi).limit_denominator()\n",
    "    num, den = frac.numerator, frac.denominator\n",
    "\n",
    "    if num == 0:\n",
    "        return \"0\"\n",
    "    elif num == den:\n",
    "        return r\"$\\pi$\"\n",
    "    elif den == 1:\n",
    "        return rf\"${num}\\pi$\"\n",
    "    elif num == 1:\n",
    "        return rf\"$\\frac{{\\pi}}{{{den}}}$\"\n",
    "    else:\n",
    "        return rf\"$\\frac{{{num}\\pi}}{{{den}}}$\"\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "for thetas in np.array(varqite.all_thetas).T:\n",
    "    ax.plot(thetas)\n",
    "ax.set_xlim(0, varqite.total_steps - 1)\n",
    "# ax.set_ylim(0, 2 * np.pi)\n",
    "# ax.set_ylim(np.pi - np.pi / 2, np.pi + np.pi / 2)\n",
    "ax.yaxis.set_major_locator(MultipleLocator(np.pi / 4))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(np.pi / 8))\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(pi_formatter))\n",
    "ax.set_title(\"Parameters per step\")\n",
    "ax.set_xlabel(\"steps\")\n",
    "ax.grid(axis=\"y\", which=\"major\")\n",
    "ax.grid(axis=\"y\", which=\"minor\", ls=\"dotted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec66ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "for Dvec_ele in np.array(varqite.Dvecs).T:\n",
    "    ax.plot(Dvec_ele)\n",
    "# ax.set_yscale(\"log\")\n",
    "# ax.set_ylim(10e-10, 1)\n",
    "ax.set_xlim(0, varqite.total_steps - 1)\n",
    "ax.set_xlabel(\"steps\")\n",
    "ax.set_title(\"Elements of $D$ per step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "for Gmat_ele in varqite.Gmats.reshape(varqite.total_steps, -1).T:\n",
    "    ax.plot(Gmat_ele)\n",
    "ax.set_xlim(0, varqite.total_steps - 1)\n",
    "ax.set_xlabel(\"steps\")\n",
    "ax.set_title(\"Elements of $G$ per step\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212c0ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Miscellany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cbed44",
   "metadata": {},
   "source": [
    "## $\\Delta E$ for $H_0$ vs $H_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get (12,000, 64) array in bitstring order (e.g. 000000, 000001, etc) of energies\n",
    "_, engs_H2 = get_all_bitstring_energies(evts=evts, hamiltonian=\"H2\")\n",
    "_, engs_H0 = get_all_bitstring_energies(evts=evts, hamiltonian=\"H0\")\n",
    "# Now sorted by energy\n",
    "sorted_engs_H2 = np.sort(engs_H2, axis=1)\n",
    "sorted_engs_H0 = np.sort(engs_H0, axis=1)\n",
    "# Difference between the lowest two energies normalized by the lowest energy\n",
    "deltaE_H2 = np.abs(\n",
    "    np.squeeze(np.diff(sorted_engs_H2[:, [0, 2]], axis=1)) / sorted_engs_H2[:, 0]\n",
    ")\n",
    "deltaE_H0 = np.abs(\n",
    "    np.squeeze(np.diff(sorted_engs_H0[:, [0, 2]], axis=1)) / sorted_engs_H0[:, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537047be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "thresh = 10\n",
    "perc_omit = 100 * np.sum(deltaE_H0 > thresh) / len(deltaE_H0)\n",
    "ax.hist(deltaE_H2[deltaE_H2 < thresh], bins=100, histtype=\"step\", label=\"$H_2$\")\n",
    "ax.hist(deltaE_H0[deltaE_H0 < thresh], bins=100, histtype=\"step\", label=\"$H_0$\")\n",
    "ax.set_ylabel(\"Counts\", fontsize=15)\n",
    "ax.set_xlim(0, thresh)\n",
    "ax.set_xlabel(r\"$\\Delta E / E_0$\", fontsize=15)\n",
    "ax.annotate(\n",
    "    f\"{perc_omit:.2f}% of $H_0$ omitted\",\n",
    "    xy=(0.5, 0.9),\n",
    "    xycoords=\"axes fraction\",\n",
    "    bbox=dict(fc=\"white\"),\n",
    ")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd707e",
   "metadata": {},
   "source": [
    "## QNode to QASM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab27edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_qasm(qnode, params):\n",
    "    \"\"\"\n",
    "    Convert a (parameterized) QNode into QASM code\n",
    "    \"\"\"\n",
    "    tape = qml.workflow.construct_tape(qnode, level=\"device\")(*params)\n",
    "    return tape.to_openqasm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bf323",
   "metadata": {},
   "source": [
    "## Decompose Pauli String Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eaf7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_set = {qml.CNOT, qml.RX, qml.RY, qml.RZ, qml.PauliX, qml.PauliY, qml.PauliZ}\n",
    "\n",
    "\n",
    "def create_circuit(pauli_string, theta_val=0.5):\n",
    "    \"\"\"\n",
    "    Draws the decomposition of the given Pauli string.\n",
    "    \"\"\"\n",
    "\n",
    "    def circuit(theta):\n",
    "        qml.PauliRot(theta, pauli_string, wires=range(len(pauli_string)))\n",
    "        return qml.probs()\n",
    "\n",
    "    qnode = qml.QNode(circuit, device=qml.device(\"default.qubit\"))\n",
    "\n",
    "    qml.draw_mpl(qml.transforms.decompose(qnode, gate_set=gate_set), decimals=4)(\n",
    "        theta_val\n",
    "    )\n",
    "    return qnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnode = create_circuit(\"ZZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnode = create_circuit(\"ZY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3947504",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnode = create_circuit(\"ZYXXZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356676da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
